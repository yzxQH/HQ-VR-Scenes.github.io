<!DOCTYPE html lang="en">
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Dense and Walkable: Highly-Quality large scenes capture for 3D Reconstruction">
  <meta name="keywords" content="VR-3D Guassian, NeRF, IBRnet,  large scenes dataset">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VR-NeRF: High-Fidelity Virtualized Walkable Spaces</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/vr-glasses.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">VR-NeRF: High-Fidelity Virtualized Walkable Spaces</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://eveneveno.github.io/lnxu">Linning Xu</a><sup>1,2</sup>,</span>
            <span class="author-block"><a href="https://notes.vasuagrawal.com">Vasu Agrawal</a><sup>1</sup>,</span>
            <span class="author-block"><a href="">William Laney</a><sup>1</sup>,</span>
            <span class="author-block"><a href="">Tony Garcia</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://www.aayushbansal.xyz">Aayush Bansal</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://changilkim.com/">Changil Kim</a><sup>1</sup>,</span>
            <span class="author-block"><a href="">Samuel Rota Bulò</a><sup>1</sup>,</span>
            <span class="author-block"><a href="">Lorenzo Porzi</a><sup>1</sup>,</span>
            <span class="author-block"><a href="">Peter Kontschieder</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://aljazbozic.github.io/">Aljaž Božič</a><sup>1</sup>,</span>
            <span class="author-block"><a href="http://dahua.site/">Dahua Lin</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://zollhoefer.com/">Michael Zollhöfer</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://richardt.name">Christian Richardt</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup> Meta</span>,
            <span class="author-block"><sup>2</sup> The Chinese University of Hong Kong</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="static/VRNeRF-SIGAsia2023.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2311.02542"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/9Q8_FssFQP4"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/facebookresearch/EyefulTower"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/poster.jpeg"> 
      
      <h2 class="subtitle has-text-centered">
        VR-NeRF brings high-fidelity walkable spaces to real-time virtual reality. 
        Our “Eyeful Tower” multi-camera rig captures spaces with high image resolution and dynamic range that approach the limits of the human visual system. 
      </h2>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container" style="text-align:center">
      <strong>Please note:</strong> These videos are encoded using HEVC with 10-bit HDR colors and are best viewed on a compatible display with HDR support, e.g. recent Apple devices.
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-apartment">
          <video poster="" id="apartment" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/apartment.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-riverview">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/riverview.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-office2">
          <video poster="" id="office2" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/office2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-workshop">
          <video poster="" id="workshop" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/workshop.mp4" type="video/mp4">
          </video>
        </div> 
        <div class="item item-kitchen">
          <video poster="" id="kitchen" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/kitchen.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-seating">
          <video poster="" id="seating" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/seating.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-table">
          <video poster="" id="table" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/table.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-office1">
          <video poster="" id="office1" autoplay controls muted loop playsinline height="100%">
            <source src="./videos/office1.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">

          <p>
            We present an end-to-end system for the high-fidelity capture, model reconstruction, and real-time rendering of walkable spaces in virtual reality using neural radiance fields.
            To this end, we designed and built a custom multi-camera rig to densely capture walkable spaces in high fidelity and with multi-view high dynamic range images in unprecedented quality and density.
            We extend instant neural graphics primitives with a novel perceptual color space for learning accurate HDR appearance, and an efficient mip-mapping mechanism for level-of-detail rendering with anti-aliasing, while carefully optimizing the trade-off between quality and speed.
            Our multi-GPU renderer enables high-fidelity volume rendering of our neural radiance field model at the full VR resolution of dual 2K×2K at 36 Hz on our custom demo machine.
            We demonstrate the quality of our results on our challenging high-fidelity datasets, and compare our method and datasets to existing baselines.
          </p>

        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Data Capture</h2>

        <video id="supp video" autoplay controls muted loop playsinline height="100%">
          <source src="./videos/capture.mov" type="video/mp4">
          <!-- <source src="./videos/VR-NeRF-with-voiceover.mp4" type="video/mp4"> -->
        </video>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">VR demo</h2>

        <video id="supp video" autoplay controls muted loop playsinline height="100%">
          <source src="./videos/hmc-demo.mp4" type="video/mp4">
          <!-- <source src="./videos/VR-NeRF-with-voiceover.mp4" type="video/mp4"> -->
        </video>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre>
      @InProceedings{VRNeRF,
        author    = {Linning Xu and
                     Vasu Agrawal and
                     William Laney and
                     Tony Garcia and
                     Aayush Bansal and
                     Changil Kim and
                     Rota Bulò, Samuel and
                     Lorenzo Porzi and
                     Peter Kontschieder and
                     Aljaž Božič and
                     Dahua Lin and
                     Michael Zollhöfer and
                     Christian Richardt},
        title     = {{VR-NeRF}: High-Fidelity Virtualized Walkable Spaces},
        booktitle = {SIGGRAPH Asia Conference Proceedings},
        year      = {2023},
        doi       = {10.1145/3610548.3618139},
        url       = {https://vr-nerf.github.io},
      }</pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            We thank the authors of <a href="https://nerfies.github.io/">Nerfies</a> that kindly open sourced the template of this website.
          </p>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
